from collections.abc import Sequence
from typing import Annotated, Any, Generic, Literal, TypeVar

import numcodecs  # type: ignore[import-untyped]
import pydantic

from reformatters.common.pydantic import FrozenBaseModel
from reformatters.common.types import TimedeltaUnits, TimestampUnits

type AttributeStr = Annotated[str, pydantic.Field(pattern=r"^[A-Z0-9].*[^.]$")]
type Sentence = Annotated[str, pydantic.Field(pattern=r"^[A-Z].*\.$")]


class DatasetAttributes(FrozenBaseModel):
    dataset_id: Annotated[str, pydantic.Field(pattern=r"^[a-zA-Z0-9-]+$")]
    dataset_version: Annotated[str, pydantic.Field(min_length=1)]
    name: AttributeStr
    description: Sentence
    attribution: Sentence
    spatial_domain: AttributeStr
    spatial_resolution: AttributeStr
    time_domain: AttributeStr
    time_resolution: AttributeStr
    forecast_domain: AttributeStr | None = None
    forecast_resolution: AttributeStr | None = None


class StatisticsApproximate(FrozenBaseModel):
    min: str | int | float
    max: str | int | float


type EnsembleStatistic = Literal["avg"]  # "spr" (spread) is also available


class DataVarAttrs(FrozenBaseModel):
    long_name: Annotated[str, pydantic.Field(min_length=1)]
    short_name: Annotated[str, pydantic.Field(min_length=1)]
    standard_name: Annotated[str, pydantic.Field(min_length=1)] | None = None
    units: Annotated[str, pydantic.Field(min_length=1)]
    comment: Annotated[str, pydantic.Field(min_length=1)] | None = None
    step_type: Literal["instant", "accum", "avg", "min", "max"]
    ensemble_statistic: EnsembleStatistic | None = None


type CfAxis = Literal["X", "Y", "Z", "T"]


class CoordinateAttrs(FrozenBaseModel):
    long_name: Annotated[str, pydantic.Field(min_length=1)] | None = None
    standard_name: Annotated[str, pydantic.Field(min_length=1)] | None = None
    axis: CfAxis | None = None
    units: TimestampUnits | TimedeltaUnits | str | None
    statistics_approximate: StatisticsApproximate | None
    comment: Annotated[str, pydantic.Field(min_length=1)] | None = None

    # Rio xarray attributes to encode spatial reference system
    crs_wkt: str | None = None
    semi_major_axis: float | None = None
    semi_minor_axis: float | None = None
    inverse_flattening: float | None = None
    reference_ellipsoid_name: str | None = None
    longitude_of_prime_meridian: float | None = None
    prime_meridian_name: str | None = None
    geographic_crs_name: str | None = None
    horizontal_datum_name: str | None = None
    grid_mapping_name: str | None = None
    spatial_ref: str | None = None
    GeoTransform: str | None = None
    false_easting: float | None = None
    false_northing: float | None = None
    latitude_of_projection_origin: float | None = None
    longitude_of_central_meridian: float | None = None
    projected_crs_name: str | None = None
    standard_parallel: tuple[float, float] | float | None = None


# numcodecs.zarr3 Codec wrappers are autogenerated and don't round trip
# in pydantic natively. Convert to dicts which is a fine format to store them.
def codecs_to_dicts(
    codecs: Sequence[numcodecs.abc.Codec],
) -> Sequence[dict[str, Any]] | None:
    if codecs is None:
        return None
    return [codec.to_dict() if hasattr(codec, "to_dict") else codec for codec in codecs]


class Encoding(pydantic.BaseModel):
    model_config = pydantic.ConfigDict(
        arbitrary_types_allowed=True,  # allow numcodecs.abc.Codec values
        frozen=True,
        strict=True,
        revalidate_instances="always",
    )

    # Could be any np.typing.DTypeLike but that type is loose and allows any string.
    # It's fine to add any valid dtype string to this literal.
    dtype: Literal["float32", "float64", "uint16", "int16", "int64", "bool"]
    chunks: tuple[int, ...] | int
    shards: tuple[int, ...] | int | None  # We don't shard coordinate arrays

    @pydantic.model_validator(mode="after")
    def validate_shards_multiple_of_chunks(self) -> "Encoding":
        if self.shards is None:
            return self

        if isinstance(self.chunks, int):
            chunks: tuple[int, ...] = (self.chunks,)
        else:
            chunks = self.chunks

        if isinstance(self.shards, int):
            shards: tuple[int, ...] = (self.shards,)
        else:
            shards = self.shards

        for chunk_size, shard_size in zip(chunks, shards, strict=True):
            if shard_size % chunk_size != 0:
                raise ValueError(
                    f"Each shard size ({shard_size}) must be a multiple of its "
                    f"corresponding chunk size ({chunk_size})"
                )
        return self

    fill_value: float | int | bool

    filters: Annotated[
        Sequence[dict[str, Any]] | None,
        pydantic.BeforeValidator(codecs_to_dicts),
    ] = None
    compressors: Sequence[dict[str, Any]] | None = None

    calendar: Literal["proleptic_gregorian"] | None = None  # For timestamps only
    # The _encoded_ units, for timestamps and timedeltas only
    # Decoded units for all variables are in DataVarAttrs
    units: TimestampUnits | TimedeltaUnits | None = None


class Coordinate(FrozenBaseModel):
    name: str
    encoding: Encoding
    attrs: CoordinateAttrs


class BaseInternalAttrs(FrozenBaseModel):
    keep_mantissa_bits: int | Literal["no-rounding"]
    deaccumulate_to_rate: bool = False


INTERNAL_ATTRS_co = TypeVar(
    "INTERNAL_ATTRS_co", bound=BaseInternalAttrs, covariant=True
)


class DataVar(FrozenBaseModel, Generic[INTERNAL_ATTRS_co]):
    name: str
    encoding: Encoding
    attrs: DataVarAttrs
    internal_attrs: INTERNAL_ATTRS_co
